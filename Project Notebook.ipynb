{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "import org.apache.spark._\n",
       "import org.apache.spark.graphx._\n",
       "import org.apache.spark.rdd.RDD\n",
       "import org.apache.spark.sql.functions._\n",
       "import org.apache.spark.sql.expressions.Window\n",
       "import org.apache.spark.sql.Row\n",
       "import org.apache.spark.sql.functions.split\n"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "import org.apache.spark._\n",
    "import org.apache.spark.graphx._\n",
    "import org.apache.spark.rdd.RDD\n",
    "import org.apache.spark.sql.functions._ \n",
    "import org.apache.spark.sql.expressions.Window\n",
    "import org.apache.spark.sql.Row\n",
    "import org.apache.spark.sql.functions.split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Données Karate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "karate_text: org.apache.spark.rdd.RDD[String] = data/soc-karate/soc-karate.mtx MapPartitionsRDD[1] at textFile at <console>:38\n"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "val karate_text = sc.textFile(\"data/soc-karate/soc-karate.mtx\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Données Facebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "file_number: String = 0\n",
       "facebook_text: org.apache.spark.rdd.RDD[String] = data/facebook_data/facebook/0.edges MapPartitionsRDD[3] at textFile at <console>:40\n"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "//choix du fichier\n",
    "var file_number = \"0\"\n",
    "var facebook_text = sc.textFile(\"data/facebook_data/facebook/\" + file_number + \".edges\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "df_karate_text: org.apache.spark.sql.DataFrame = [value: string]\n",
       "df_karate_text: org.apache.spark.sql.DataFrame = [value: string]\n",
       "df_karate_text: org.apache.spark.sql.DataFrame = [value: string]\n",
       "df_karate_text: org.apache.spark.sql.DataFrame = [value: string]\n",
       "df_karate_splitted: org.apache.spark.sql.DataFrame = [srcId: string, dstID: string]\n",
       "rows: org.apache.spark.rdd.RDD[org.apache.spark.sql.Row] = MapPartitionsRDD[13] at rdd at <console>:51\n",
       "karate_edges: org.apache.spark.rdd.RDD[org.apache.spark.graphx.Edge[Int]] = MapPartitionsRDD[14] at map at <console>:53\n"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "var df_karate_text = karate_text.toDF.withColumn(\"id\",monotonicallyIncreasingId)\n",
    "\n",
    "\n",
    "df_karate_text = df_karate_text.withColumn(\"rank\", row_number().over(Window.orderBy(\"id\")))\n",
    "df_karate_text = df_karate_text.filter(df_karate_text(\"rank\")>24)\n",
    "df_karate_text = df_karate_text.drop(\"id\",\"rank\")\n",
    "\n",
    "val df_karate_splitted = df_karate_text.withColumn(\"_tmp\", split($\"value\", \"\\\\ \")).select(\n",
    "  $\"_tmp\".getItem(0).as(\"srcId\"),\n",
    "  $\"_tmp\".getItem(1).as(\"dstID\"),\n",
    ")\n",
    "\n",
    "val rows: RDD[Row] = df_karate_splitted.rdd\n",
    "\n",
    "var karate_edges = rows.map{ case Row(src:String, dist : String) => Edge(src.toLong, dist.toLong,1)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "facebook_text: org.apache.spark.rdd.RDD[String] = data/facebook_data/facebook/0.edges MapPartitionsRDD[16] at textFile at <console>:41\n",
       "df_facebook_text: org.apache.spark.sql.DataFrame = [value: string]\n",
       "df_facebook_text_splitted: org.apache.spark.sql.DataFrame = [srcId: string, dstID: string]\n",
       "facebook_rows: org.apache.spark.rdd.RDD[org.apache.spark.sql.Row] = MapPartitionsRDD[21] at rdd at <console>:49\n",
       "facebook_edges: org.apache.spark.rdd.RDD[org.apache.spark.graphx.Edge[Int]] = MapPartitionsRDD[22] at map at <console>:51\n"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "var facebook_text = sc.textFile(\"data/facebook_data/facebook/\" + file_number + \".edges\")\n",
    "var df_facebook_text = facebook_text.toDF()\n",
    "\n",
    "var df_facebook_text_splitted = df_facebook_text.withColumn(\"_tmp\", split($\"value\", \"\\\\ \")).select(\n",
    "  $\"_tmp\".getItem(0).as(\"srcId\"),\n",
    "  $\"_tmp\".getItem(1).as(\"dstID\"),\n",
    ")\n",
    "\n",
    "val facebook_rows: RDD[Row] = df_facebook_text_splitted.rdd\n",
    "\n",
    "var facebook_edges = facebook_rows.map{ case Row(src:String, dist : String) => Edge(src.toLong, dist.toLong,1)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation du graphe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "chosen_edges: org.apache.spark.rdd.RDD[org.apache.spark.graphx.Edge[Int]] = MapPartitionsRDD[14] at map at <console>:53\n"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "var chosen_edges = karate_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "default_user: (Int, Int) = (0,0)\n",
       "graph: org.apache.spark.graphx.Graph[(Int, Int),Int] = org.apache.spark.graphx.impl.GraphImpl@1cf734a7\n"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "var default_user=(0, 0)\n",
    "var graph = Graph.fromEdges(chosen_edges, default_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "res0: Array[org.apache.spark.graphx.Edge[Int]] = Array(Edge(2,1,1), Edge(3,1,1), Edge(3,2,1), Edge(4,1,1), Edge(4,2,1), Edge(4,3,1), Edge(5,1,1), Edge(6,1,1), Edge(7,1,1), Edge(7,5,1), Edge(7,6,1), Edge(8,1,1), Edge(8,2,1), Edge(8,3,1), Edge(8,4,1), Edge(9,1,1), Edge(9,3,1), Edge(10,3,1), Edge(11,1,1), Edge(11,5,1), Edge(11,6,1), Edge(12,1,1), Edge(13,1,1), Edge(13,4,1), Edge(14,1,1), Edge(14,2,1), Edge(14,3,1), Edge(14,4,1), Edge(17,6,1), Edge(17,7,1), Edge(18,1,1), Edge(18,2,1), Edge(20,1,1), Edge(20,2,1), Edge(22,1,1), Edge(22,2,1), Edge(26,24,1), Edge(26,25,1), Edge(28,3,1), Edge(28,24,1), Edge(28,25,1), Edge(29,3,1), Edge(30,24,1), Edge(30,27,1), Edge(31,2,1), Edge(31,9,1), Edge(32,1,1), Edge(32,25,1), Edge(32,26,1), Edge(32,29,1), Edge(33,3,1), Edge(33,9,1), Edge(33,15,1), Edge(33...\n"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "graph.edges.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "res1: Array[(org.apache.spark.graphx.VertexId, (Int, Int))] = Array((20,(0,0)), (13,(0,0)), (19,(0,0)), (34,(0,0)), (15,(0,0)), (4,(0,0)), (21,(0,0)), (16,(0,0)), (22,(0,0)), (25,(0,0)), (28,(0,0)), (29,(0,0)), (11,(0,0)), (14,(0,0)), (32,(0,0)), (30,(0,0)), (24,(0,0)), (27,(0,0)), (33,(0,0)), (23,(0,0)), (1,(0,0)), (6,(0,0)), (17,(0,0)), (3,(0,0)), (7,(0,0)), (9,(0,0)), (8,(0,0)), (12,(0,0)), (18,(0,0)), (31,(0,0)), (26,(0,0)), (10,(0,0)), (5,(0,0)), (2,(0,0)))\n"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "graph.vertices.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcul des degrés des noeuds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "newgraph: org.apache.spark.graphx.Graph[(Int, Int),Int] = org.apache.spark.graphx.impl.GraphImpl@46889d8\n"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "val newgraph = graph.outerJoinVertices(graph.degrees)((index,_,deg) => (index.toInt,deg.get))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "res2: Array[org.apache.spark.graphx.EdgeTriplet[(Int, Int),Int]] = Array(((2,(2,9)),(1,(1,16)),1), ((3,(3,10)),(1,(1,16)),1), ((3,(3,10)),(2,(2,9)),1), ((4,(4,6)),(1,(1,16)),1), ((4,(4,6)),(2,(2,9)),1), ((4,(4,6)),(3,(3,10)),1), ((5,(5,3)),(1,(1,16)),1), ((6,(6,4)),(1,(1,16)),1), ((7,(7,4)),(1,(1,16)),1), ((7,(7,4)),(5,(5,3)),1), ((7,(7,4)),(6,(6,4)),1), ((8,(8,4)),(1,(1,16)),1), ((8,(8,4)),(2,(2,9)),1), ((8,(8,4)),(3,(3,10)),1), ((8,(8,4)),(4,(4,6)),1), ((9,(9,5)),(1,(1,16)),1), ((9,(9,5)),(3,(3,10)),1), ((10,(10,2)),(3,(3,10)),1), ((11,(11,3)),(1,(1,16)),1), ((11,(11,3)),(5,(5,3)),1), ((11,(11,3)),(6,(6,4)),1), ((12,(12,1)),(1,(1,16)),1), ((13,(13,2)),(1,(1,16)),1), ((13,(13,2)),(4,(4,6)),1), ((14,(14,5)),(1,(1,16)),1), ((14,(14,5)),(2,(2,9)),1), ((14,(14,5)),(3,(3,10)),1), ((14,(14,5...\n"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "newgraph.triplets.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "res3: Array[(org.apache.spark.graphx.VertexId, (Int, Int))] = Array((20,(20,3)), (13,(13,2)), (19,(19,2)), (34,(34,17)), (15,(15,2)), (4,(4,6)), (21,(21,2)), (16,(16,2)), (22,(22,2)), (25,(25,3)), (28,(28,4)), (29,(29,3)), (11,(11,3)), (14,(14,5)), (32,(32,6)), (30,(30,4)), (24,(24,5)), (27,(27,2)), (33,(33,12)), (23,(23,2)), (1,(1,16)), (6,(6,4)), (17,(17,2)), (3,(3,10)), (7,(7,4)), (9,(9,5)), (8,(8,4)), (12,(12,1)), (18,(18,2)), (31,(31,4)), (26,(26,3)), (10,(10,2)), (5,(5,3)), (2,(2,9)))\n"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "newgraph.vertices.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ETAPE 1: Variables utiles pour calculer le gain en modularité lors de la suppression d'un noeud d'une communauté"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "sigmaIn1: (i: Int, comId: Int, graph: org.apache.spark.graphx.Graph[(Int, Int),Int])Double\n",
       "sigmaTot1: (i: Int, comId: Int, graph: org.apache.spark.graphx.Graph[(Int, Int),Int])Double\n"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "def sigmaIn1(i:Int, comId: Int, graph : Graph[(Int, Int),Int]): Double = {\n",
    "    var graphVar = graph.triplets.filter((triplet => (triplet.srcAttr._1==comId && triplet.dstAttr._1==comId) &&\n",
    "                                                    !(triplet.srcId==i || triplet.dstId==i)))\n",
    "    return graphVar.count.toDouble\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "def sigmaTot1(i:Int, comId: Int, graph : Graph[(Int, Int),Int]): Double = {\n",
    "    var graphVar = graph.triplets.filter((triplet => \n",
    "    (triplet.srcAttr._1==comId && triplet.srcId !=i && triplet.dstAttr._1 !=comId) || \n",
    "    (triplet.srcAttr._1!=comId && triplet.dstAttr._1==comId && triplet.dstId !=i) ||\n",
    "    (triplet.srcId==i && triplet.dstAttr._1==comId) || \n",
    "    (triplet.srcAttr._1==comId && triplet.dstId==i ) \n",
    "    ))\n",
    "    return graphVar.count.toDouble\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ETAPE 2: Variables utiles pour calculer le gain en modularité lors de l'ajout d'un noeud à une communauté"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "sigmaIn2: (comId: Int, graph: org.apache.spark.graphx.Graph[(Int, Int),Int])Double\n",
       "sigmaTot2: (comId: Int, graph: org.apache.spark.graphx.Graph[(Int, Int),Int])Double\n"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "def sigmaIn2(comId: Int, graph : Graph[(Int, Int),Int]): Double = {\n",
    "    var graphVar = graph.triplets.filter((triplet => triplet.srcAttr._1==comId && triplet.dstAttr._1==comId))\n",
    "    return graphVar.count.toDouble\n",
    "}\n",
    "\n",
    "\n",
    "def sigmaTot2(comId: Int, graph : Graph[(Int, Int),Int]): Double = {\n",
    "    var graphVar = graph.triplets.filter((triplet => (triplet.srcAttr._1==comId && triplet.dstAttr._1!=comId)||(triplet.srcAttr._1!=comId && triplet.dstAttr._1==comId)))\n",
    "    return graphVar.count.toDouble\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables utiles au 2 étapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "ki: (i: Int, graph: org.apache.spark.graphx.Graph[(Int, Int),Int])Double\n",
       "kiin: (i: Int, comId: Int, graph: org.apache.spark.graphx.Graph[(Int, Int),Int])Double\n"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "def ki(i: Int, graph : Graph[(Int, Int),Int]): Double = {\n",
    "    var graphVar = graph.triplets.filter((triplet => triplet.srcId==i || triplet.dstId==i))\n",
    "    return graphVar.count.toDouble\n",
    "}\n",
    "\n",
    "def kiin(i:Int, comId : Int, graph : Graph[(Int, Int),Int]) : Double = {\n",
    "    var graphVar = graph.triplets.filter((triplet => (triplet.srcId==i && triplet.dstAttr._1==comId) ||(triplet.srcAttr._1==comId && triplet.dstId==i)))\n",
    "    return graphVar.count.toDouble\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcul du différentiel de modularité"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "dq: (sigmain: Double, sigmatot: Double, kivar: Double, kiinvar: Double, m: Double)Double\n"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "def dq(sigmain:Double, sigmatot:Double, kivar:Double, kiinvar:Double, m:Double):Double = {\n",
    "    return (((sigmain+kiinvar)/(2*m) - scala.math.pow((sigmatot+kivar)/(2*m),2)) - (sigmain/(2*m) - scala.math.pow(sigmatot/(2*m),2) - scala.math.pow(kivar/(2*m),2)))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "maxCom: (setDq: Set[(Int, Double)])(Int, Double)\n"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "def maxCom(setDq : Set[(Int, Double)]) : (Int, Double) = {\n",
    "    var max = -1000.0\n",
    "    var ind = -1\n",
    "    setDq.foreach(x => {\n",
    "        if (x._2>max)\n",
    "        {\n",
    "            ind=x._1\n",
    "            max=x._2\n",
    "        }\n",
    "    })\n",
    "    return (ind,max)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "moveItoC: (i: Int, comId: Int, graph: org.apache.spark.graphx.Graph[(Int, Int),Int])org.apache.spark.graphx.Graph[(Int, Int),Int]\n"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "def moveItoC(i:Int, comId : Int, graph:Graph[(Int, Int),Int]) : Graph[(Int, Int),Int] = {\n",
    "    val newVertices = graph.mapVertices { case (id, attr) => if (id==i) (comId, attr._2) else attr }\n",
    "    return newVertices\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "q: (graph: org.apache.spark.graphx.Graph[(Int, Int),Int])Double\n"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "def q(graph:Graph[(Int,Int),Int]) : Double = {\n",
    "    var m = graph.edges.count()\n",
    "    var vertices = graph.vertices.collect\n",
    "    var q=0.0\n",
    "    vertices.foreach{ case t1 => {\n",
    "        vertices.foreach{ case t2 => {\n",
    "\n",
    "            var isEdge = graph.edges.filter(e => (e.srcId == t1._1 &&e.dstId==t2._1) || (e.dstId==t2._1 && e.srcId==t1._1)).count.toDouble\n",
    "            if (t1._2._1 == t2._2._1){\n",
    "                q+= isEdge - t1._2._2.toDouble*t2._2._2.toDouble/(2*m)\n",
    "            }\n",
    "            \n",
    "\n",
    "            }\n",
    "        }   \n",
    "    \n",
    "        }\n",
    "    }\n",
    "    return q/(2*m)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "communities: (graph: org.apache.spark.graphx.Graph[(Int, Int),Int])org.apache.spark.graphx.Graph[(Int, Int),Int]\n"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "def communities(graph:Graph[(Int,Int),Int]) : Graph[(Int,Int),Int] = {\n",
    "    var currentGraph = graph\n",
    "    var nbVertices = graph.vertices.count\n",
    "    var m = graph.edges.count\n",
    "\n",
    "    var i = 0\n",
    "    var keepGoing = true\n",
    "    var j=0\n",
    "    for (j<- 1 to 10){\n",
    "        println(j)\n",
    "        keepGoing=false\n",
    "        println(((currentGraph.vertices.collect { case t => t._2._1 }).collect.distinct).size)\n",
    "        for (i<- 1 to nbVertices.toInt){\n",
    "            println(\"Noeud considéré : \"+i+ '\\n')\n",
    "            /*get the community and ki */\n",
    "            var vertice = (currentGraph.vertices.collect{ case t if t._1 == i => t._2}).collect\n",
    "            var comId = vertice(0)._1\n",
    "            println(\"Communauté de \"+i+\" : \"+comId)\n",
    "            var kivar = vertice(0)._2\n",
    "\n",
    "            /* calculate dq1 */\n",
    "            var kiin1 = kiin(i, comId, currentGraph)\n",
    "            var sigmain1 = sigmaIn1(i, comId, currentGraph)\n",
    "            var sigmatot1 = sigmaTot1(i, comId, currentGraph)\n",
    "            var dq1 = dq(sigmain1, sigmatot1, kivar, kiin1, m)\n",
    "\n",
    "            /*look all combis : we need to know how many communities are left and which one*/\n",
    "            var communities = (currentGraph.vertices.collect { case t => t._2._1 }).collect.distinct\n",
    "\n",
    "            var setDq =Set(): Set[(Int,Double)]\n",
    "            communities.foreach( a => {\n",
    "                if (a!=comId){\n",
    "                    var sigmain2 = sigmaIn2(a, currentGraph)\n",
    "                    var sigmatot2 = sigmaTot2(a, currentGraph)\n",
    "                    var kiin2 = kiin(i,a, currentGraph)\n",
    "                    var dq2 = dq(sigmain2, sigmatot2, kivar, kiin2, m)\n",
    "                    setDq+=((a.toInt,dq2))\n",
    "                }\n",
    "            })\n",
    "\n",
    "            /* get best combi and move if larger than 0 */\n",
    "            var bestCombi = maxCom(setDq)\n",
    "            if (bestCombi._2.toDouble > 0.0001 ) {\n",
    "                \n",
    "                var communities = (currentGraph.vertices.collect { case t => t._2._1 }).collect.distinct\n",
    "                println(\"On met \"+ i +\" dans \"+bestCombi._1+ '\\n')\n",
    "                var updatedGraph = moveItoC(i, bestCombi._1, currentGraph)\n",
    "                currentGraph=updatedGraph\n",
    "\n",
    "                /*Un changement est fait*/\n",
    "                keepGoing=true\n",
    "\n",
    "            }\n",
    "            \n",
    "    }\n",
    "    println(\"Q = \"+q(currentGraph))\n",
    "    }\n",
    "    return currentGraph\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "34\n",
      "Noeud considéré : 1\n",
      "\n",
      "Communauté de 1 : 1\n",
      "On met 1 dans 12\n",
      "\n",
      "Noeud considéré : 2\n",
      "\n",
      "Communauté de 2 : 2\n",
      "On met 2 dans 22\n",
      "\n",
      "Noeud considéré : 3\n",
      "\n",
      "Communauté de 3 : 3\n",
      "On met 3 dans 10\n",
      "\n",
      "Noeud considéré : 4\n",
      "\n",
      "Communauté de 4 : 4\n",
      "On met 4 dans 13\n",
      "\n",
      "Noeud considéré : 5\n",
      "\n",
      "Communauté de 5 : 5\n",
      "On met 5 dans 11\n",
      "\n",
      "Noeud considéré : 6\n",
      "\n",
      "Communauté de 6 : 6\n",
      "On met 6 dans 17\n",
      "\n",
      "Noeud considéré : 7\n",
      "\n",
      "Communauté de 7 : 7\n",
      "On met 7 dans 17\n",
      "\n",
      "Noeud considéré : 8\n",
      "\n",
      "Communauté de 8 : 8\n",
      "On met 8 dans 13\n",
      "\n",
      "Noeud considéré : 9\n",
      "\n",
      "Communauté de 9 : 9\n",
      "On met 9 dans 31\n",
      "\n",
      "Noeud considéré : 10\n",
      "\n",
      "Communauté de 10 : 10\n",
      "On met 10 dans 34\n",
      "\n",
      "Noeud considéré : 11\n",
      "\n",
      "Communauté de 11 : 11\n",
      "On met 11 dans 17\n",
      "\n",
      "Noeud considéré : 12\n",
      "\n",
      "Communauté de 12 : 12\n",
      "Noeud considéré : 13\n",
      "\n",
      "Communauté de 13 : 13\n",
      "On met 13 dans 12\n",
      "\n",
      "Noeud considéré : 14\n",
      "\n",
      "Communauté de 14 : 14\n",
      "On met 14 dans 13\n",
      "\n",
      "Noeud considéré : 15\n",
      "\n",
      "Communauté de 15 : 15\n",
      "On met 15 dans 33\n",
      "\n",
      "Noeud considéré : 16\n",
      "\n",
      "Communauté de 16 : 16\n",
      "On met 16 dans 33\n",
      "\n",
      "Noeud considéré : 17\n",
      "\n",
      "Communauté de 17 : 17\n",
      "Noeud considéré : 18\n",
      "\n",
      "Communauté de 18 : 18\n",
      "On met 18 dans 22\n",
      "\n",
      "Noeud considéré : 19\n",
      "\n",
      "Communauté de 19 : 19\n",
      "On met 19 dans 33\n",
      "\n",
      "Noeud considéré : 20\n",
      "\n",
      "Communauté de 20 : 20\n",
      "On met 20 dans 22\n",
      "\n",
      "Noeud considéré : 21\n",
      "\n",
      "Communauté de 21 : 21\n",
      "On met 21 dans 33\n",
      "\n",
      "Noeud considéré : 22\n",
      "\n",
      "Communauté de 22 : 22\n",
      "On met 22 dans 12\n",
      "\n",
      "Noeud considéré : 23\n",
      "\n",
      "Communauté de 23 : 23\n",
      "On met 23 dans 33\n",
      "\n",
      "Noeud considéré : 24\n",
      "\n",
      "Communauté de 24 : 24\n",
      "On met 24 dans 26\n",
      "\n",
      "Noeud considéré : 25\n",
      "\n",
      "Communauté de 25 : 25\n",
      "On met 25 dans 28\n",
      "\n",
      "Noeud considéré : 26\n",
      "\n",
      "Communauté de 26 : 26\n",
      "On met 26 dans 28\n",
      "\n",
      "Noeud considéré : 27\n",
      "\n",
      "Communauté de 27 : 27\n",
      "On met 27 dans 30\n",
      "\n",
      "Noeud considéré : 28\n",
      "\n",
      "Communauté de 28 : 28\n",
      "On met 28 dans 26\n",
      "\n",
      "Noeud considéré : 29\n",
      "\n",
      "Communauté de 29 : 29\n",
      "On met 29 dans 32\n",
      "\n",
      "Noeud considéré : 30\n",
      "\n",
      "Communauté de 30 : 30\n",
      "On met 30 dans 26\n",
      "\n",
      "Noeud considéré : 31\n",
      "\n",
      "Communauté de 31 : 31\n",
      "On met 31 dans 22\n",
      "\n",
      "Noeud considéré : 32\n",
      "\n",
      "Communauté de 32 : 32\n",
      "On met 32 dans 28\n",
      "\n",
      "Noeud considéré : 33\n",
      "\n",
      "Communauté de 33 : 33\n",
      "On met 33 dans 26\n",
      "\n",
      "Noeud considéré : 34\n",
      "\n",
      "Communauté de 34 : 34\n",
      "On met 34 dans 33\n",
      "\n",
      "Q = 0.0384615384615385\n",
      "2\n",
      "13\n",
      "Noeud considéré : 1\n",
      "\n",
      "Communauté de 1 : 12\n",
      "On met 1 dans 17\n",
      "\n",
      "Noeud considéré : 2\n",
      "\n",
      "Communauté de 2 : 22\n",
      "On met 2 dans 13\n",
      "\n",
      "Noeud considéré : 3\n",
      "\n",
      "Communauté de 3 : 10\n",
      "On met 3 dans 13\n",
      "\n",
      "Noeud considéré : 4\n",
      "\n",
      "Communauté de 4 : 13\n",
      "On met 4 dans 12\n",
      "\n",
      "Noeud considéré : 5\n",
      "\n",
      "Communauté de 5 : 11\n",
      "On met 5 dans 17\n",
      "\n",
      "Noeud considéré : 6\n",
      "\n",
      "Communauté de 6 : 17\n",
      "Noeud considéré : 7\n",
      "\n",
      "Communauté de 7 : 17\n",
      "Noeud considéré : 8\n",
      "\n",
      "Communauté de 8 : 13\n",
      "On met 8 dans 12\n",
      "\n",
      "Noeud considéré : 9\n",
      "\n",
      "Communauté de 9 : 31\n",
      "On met 9 dans 22\n",
      "\n",
      "Noeud considéré : 10\n",
      "\n",
      "Communauté de 10 : 34\n",
      "On met 10 dans 33\n",
      "\n",
      "Noeud considéré : 11\n",
      "\n",
      "Communauté de 11 : 17\n",
      "Noeud considéré : 12\n",
      "\n",
      "Communauté de 12 : 12\n",
      "On met 12 dans 17\n",
      "\n",
      "Noeud considéré : 13\n",
      "\n",
      "Communauté de 13 : 12\n",
      "On met 13 dans 17\n",
      "\n",
      "Noeud considéré : 14\n",
      "\n",
      "Communauté de 14 : 13\n",
      "On met 14 dans 12\n",
      "\n",
      "Noeud considéré : 15\n",
      "\n",
      "Communauté de 15 : 33\n",
      "On met 15 dans 26\n",
      "\n",
      "Noeud considéré : 16\n",
      "\n",
      "Communauté de 16 : 33\n",
      "On met 16 dans 26\n",
      "\n",
      "Noeud considéré : 17\n",
      "\n",
      "Communauté de 17 : 17\n",
      "Noeud considéré : 18\n",
      "\n",
      "Communauté de 18 : 22\n",
      "On met 18 dans 17\n",
      "\n",
      "Noeud considéré : 19\n",
      "\n",
      "Communauté de 19 : 33\n",
      "On met 19 dans 26\n",
      "\n",
      "Noeud considéré : 20\n",
      "\n",
      "Communauté de 20 : 22\n",
      "On met 20 dans 17\n",
      "\n",
      "Noeud considéré : 21\n",
      "\n",
      "Communauté de 21 : 33\n",
      "On met 21 dans 26\n",
      "\n",
      "Noeud considéré : 22\n",
      "\n",
      "Communauté de 22 : 12\n",
      "On met 22 dans 17\n",
      "\n",
      "Noeud considéré : 23\n",
      "\n",
      "Communauté de 23 : 33\n",
      "On met 23 dans 26\n",
      "\n",
      "Noeud considéré : 24\n",
      "\n",
      "Communauté de 24 : 26\n",
      "On met 24 dans 28\n",
      "\n",
      "Noeud considéré : 25\n",
      "\n",
      "Communauté de 25 : 28\n",
      "On met 25 dans 26\n",
      "\n",
      "Noeud considéré : 26\n",
      "\n",
      "Communauté de 26 : 28\n",
      "On met 26 dans 26\n",
      "\n",
      "Noeud considéré : 27\n",
      "\n",
      "Communauté de 27 : 30\n",
      "On met 27 dans 33\n",
      "\n",
      "Noeud considéré : 28\n",
      "\n",
      "Communauté de 28 : 26\n",
      "On met 28 dans 28\n",
      "\n",
      "Noeud considéré : 29\n",
      "\n",
      "Communauté de 29 : 32\n",
      "On met 29 dans 28\n",
      "\n",
      "Noeud considéré : 30\n",
      "\n",
      "Communauté de 30 : 26\n"
     ]
    }
   ],
   "source": [
    "var a = communities(newgraph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST\n",
    "\n",
    "On veut savoir s'il est intéressant de placer le noeud 1 dans la communauté 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "sigmain2: Double = 0.0\n",
       "sigmatot2: Double = 1.0\n",
       "kivar: Double = 16.0\n",
       "kiinvar: Double = 1.0\n",
       "m: Long = 78\n"
      ]
     },
     "metadata": {},
     "execution_count": 197
    }
   ],
   "source": [
    "var sigmain2 = sigmaIn2(12,newgraph)\n",
    "var sigmatot2 = sigmaTot2(12,newgraph)\n",
    "var kivar = ki(1, newgraph)\n",
    "var kiinvar = kiin(1,12,newgraph)\n",
    "var m=newgraph.edges.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "dq2: Double = 0.00509533201840894\n"
      ]
     },
     "metadata": {},
     "execution_count": 198
    }
   ],
   "source": [
    "var dq2 = dq(sigmain2, sigmatot2, kivar, kiinvar, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "a: Double = -0.04980276134122287\n"
      ]
     },
     "metadata": {},
     "execution_count": 199
    }
   ],
   "source": [
    "var a = q(newgraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "graphCible: org.apache.spark.graphx.Graph[(Int, Int),Int] = org.apache.spark.graphx.impl.GraphImpl@648efdb2\n"
      ]
     },
     "metadata": {},
     "execution_count": 200
    }
   ],
   "source": [
    "var graphCible = moveItoC(1,12,newgraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "b: Double = -0.04470742932281392\n"
      ]
     },
     "metadata": {},
     "execution_count": 201
    }
   ],
   "source": [
    "var b = q(graphCible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "res51: Double = -0.04470742932281393\n"
      ]
     },
     "metadata": {},
     "execution_count": 202
    }
   ],
   "source": [
    "a+dq2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "-0.0013149243918474714\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "sigmain2: Double = 0.0\n",
       "sigmatot2: Double = 2.0\n",
       "kivar: Double = 16.0\n",
       "kiinvar2: Double = 1.0\n",
       "m: Double = 78.0\n",
       "dq2: Double = 0.003780407626561469\n",
       "sigmain1: Double = 0.0\n",
       "sigmatot1: Double = 1.0\n",
       "kiinvar1: Double = 1.0\n",
       "dq1: Double = 0.00509533201840894\n",
       "dqtot: Double = -0.0013149243918474714\n"
      ]
     },
     "metadata": {},
     "execution_count": 203
    }
   ],
   "source": [
    "var sigmain2 = sigmaIn2(13,graphCible)\n",
    "var sigmatot2 = sigmaTot2(13,graphCible)\n",
    "var kivar = ki(1, graphCible)\n",
    "var kiinvar2 = kiin(1,13,graphCible)\n",
    "var m=graphCible.edges.count.toDouble\n",
    "var dq2 = dq(sigmain2, sigmatot2, kivar, kiinvar2, m)\n",
    "\n",
    "var sigmain1 = sigmaIn1(1,12,graphCible)\n",
    "var sigmatot1 = sigmaTot1(1,12,graphCible)\n",
    "var kiinvar1 = kiin(1,12,graphCible)\n",
    "\n",
    "var dq1= dq(sigmain1, sigmatot1, kivar, kiinvar1, m)\n",
    "\n",
    "var dqtot = dq2 - dq1\n",
    "\n",
    "println(dqtot)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "graphCible2: org.apache.spark.graphx.Graph[(Int, Int),Int] = org.apache.spark.graphx.impl.GraphImpl@18cb88ee\n",
       "c: Double = -0.046022353714661395\n"
      ]
     },
     "metadata": {},
     "execution_count": 205
    }
   ],
   "source": [
    "var graphCible2 = moveItoC(1,13,graphCible)\n",
    "var c =q(graphCible2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "res54: Double = -0.0013149243918474732\n"
      ]
     },
     "metadata": {},
     "execution_count": 206
    }
   ],
   "source": [
    "c-b"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}