{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark._\n",
       "import org.apache.spark.graphx._\n",
       "import org.apache.spark.rdd.RDD\n",
       "import org.apache.spark.sql.functions._\n",
       "import org.apache.spark.sql.expressions.Window\n",
       "import org.apache.spark.sql.Row\n"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark._\n",
    "import org.apache.spark.graphx._\n",
    "import org.apache.spark.rdd.RDD\n",
    "import org.apache.spark.sql.functions._ \n",
    "import org.apache.spark.sql.expressions.Window\n",
    "import org.apache.spark.sql.Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "karate_graph: org.apache.spark.rdd.RDD[String] = data/soc-karate/soc-karate.mtx MapPartitionsRDD[146] at textFile at <console>:77\n"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val karate_graph = sc.textFile(\"data/soc-karate/soc-karate.mtx\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On cherche juste à supprimer les permières lignes d'intro pour ne garder que les datas..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df_karate: org.apache.spark.sql.DataFrame = [value: string, id: bigint]\n"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var df_karate = karate_graph.toDF.withColumn(\"id\",monotonicallyIncreasingId)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df_karate: org.apache.spark.sql.DataFrame = [value: string, id: bigint ... 1 more field]\n"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_karate = df_karate.withColumn(\"rank\", row_number().over(Window.orderBy(\"id\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------+----------+----+\n",
      "|value                                                                           |id        |rank|\n",
      "+--------------------------------------------------------------------------------+----------+----+\n",
      "|%%MatrixMarket matrix coordinate pattern symmetric                              |0         |1   |\n",
      "|%-------------------------------------------------------------------------------|1         |2   |\n",
      "|% UF Sparse Matrix Collection, Tim Davis                                        |2         |3   |\n",
      "|% http://www.cise.ufl.edu/research/sparse/matrices/Newman/karate                |3         |4   |\n",
      "|% name: Newman/karate                                                           |4         |5   |\n",
      "|% [Karate club, from Wayne Zachary, 1977]                                       |5         |6   |\n",
      "|% id: 2399                                                                      |6         |7   |\n",
      "|% date: 1977                                                                    |7         |8   |\n",
      "|% author: W. Zachary                                                            |8         |9   |\n",
      "|% ed: M. Newman                                                                 |9         |10  |\n",
      "|% fields: name title A id date author kind notes ed                             |10        |11  |\n",
      "|% kind: undirected graph                                                        |11        |12  |\n",
      "|%-------------------------------------------------------------------------------|12        |13  |\n",
      "|% notes:                                                                        |13        |14  |\n",
      "|% Network collection from M. Newman                                             |14        |15  |\n",
      "|% http://www-personal.umich.edu/~mejn/netdata/                                  |15        |16  |\n",
      "|%                                                                               |16        |17  |\n",
      "|% The graph \"karate\" contains the network of friendships between the 34         |17        |18  |\n",
      "|% members of a karate club at a US university, as described by Wayne Zachary    |8589934592|19  |\n",
      "|% in 1977.  If you use these data in your work, please cite W. W. Zachary, An   |8589934593|20  |\n",
      "|% information flow model for conflict and fission in small groups, Journal of   |8589934594|21  |\n",
      "|% Anthropological Research 33, 452-473 (1977).                                  |8589934595|22  |\n",
      "|%-------------------------------------------------------------------------------|8589934596|23  |\n",
      "|34 34 78                                                                        |8589934597|24  |\n",
      "|2 1                                                                             |8589934598|25  |\n",
      "|3 1                                                                             |8589934599|26  |\n",
      "|4 1                                                                             |8589934600|27  |\n",
      "|5 1                                                                             |8589934601|28  |\n",
      "|6 1                                                                             |8589934602|29  |\n",
      "|7 1                                                                             |8589934603|30  |\n",
      "+--------------------------------------------------------------------------------+----------+----+\n",
      "only showing top 30 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_karate.show(30,false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df_karate: org.apache.spark.sql.DataFrame = [value: string, id: bigint ... 1 more field]\n"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_karate = df_karate.filter(df_karate(\"rank\")>24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df_karate: org.apache.spark.sql.DataFrame = [value: string]\n"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_karate = df_karate.drop(\"id\",\"rank\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|value|\n",
      "+-----+\n",
      "|  2 1|\n",
      "|  3 1|\n",
      "|  4 1|\n",
      "|  5 1|\n",
      "|  6 1|\n",
      "+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_karate.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.functions.split\n",
       "df_karate_splitted: org.apache.spark.sql.DataFrame = [srcId: string, dstID: string]\n"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions.split\n",
    "\n",
    "val df_karate_splitted = df_karate.withColumn(\"_tmp\", split($\"value\", \"\\\\ \")).select(\n",
    "  $\"_tmp\".getItem(0).as(\"srcId\"),\n",
    "  $\"_tmp\".getItem(1).as(\"dstID\"),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|srcId|dstID|\n",
      "+-----+-----+\n",
      "|    2|    1|\n",
      "|    3|    1|\n",
      "|    4|    1|\n",
      "|    5|    1|\n",
      "|    6|    1|\n",
      "+-----+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_karate_splitted.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rows: org.apache.spark.rdd.RDD[org.apache.spark.sql.Row] = MapPartitionsRDD[180] at rdd at <console>:92\n"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val rows: RDD[Row] = df_karate_splitted.rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RDD_edges: org.apache.spark.rdd.RDD[(String, String)] = MapPartitionsRDD[211] at map at <console>:93\n"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val RDD_edges = df_karate_splitted.rdd\n",
    "  .map(row => {\n",
    "    val srcId = row.getString(0)\n",
    "    val dstID = row.getString(1)\n",
    "    (srcId,dstID)\n",
    "  })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|srcId|dstID|\n",
      "+-----+-----+\n",
      "|    2|    1|\n",
      "|    3|    1|\n",
      "|    4|    1|\n",
      "|    5|    1|\n",
      "|    6|    1|\n",
      "|    7|    1|\n",
      "|    8|    1|\n",
      "|    9|    1|\n",
      "|   11|    1|\n",
      "|   12|    1|\n",
      "|   13|    1|\n",
      "|   14|    1|\n",
      "|   18|    1|\n",
      "|   20|    1|\n",
      "|   22|    1|\n",
      "|   32|    1|\n",
      "|    3|    2|\n",
      "|    4|    2|\n",
      "|    8|    2|\n",
      "|   14|    2|\n",
      "+-----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_karate_splitted.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dstId: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [dstId: string]\n",
       "srcId: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [srcId: string]\n"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val dstId = df_karate_splitted.select(df_karate_splitted(\"dstId\")).distinct\n",
    "val srcId = df_karate_splitted.select(df_karate_splitted(\"srcId\")).distinct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|srcId|\n",
      "+-----+\n",
      "|    2|\n",
      "|    3|\n",
      "|    4|\n",
      "|    5|\n",
      "|    6|\n",
      "|    7|\n",
      "|    8|\n",
      "|    9|\n",
      "|   11|\n",
      "|   12|\n",
      "+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "srcId.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "<console>",
     "evalue": "81: error: type mismatch;",
     "output_type": "error",
     "traceback": [
      "<console>:81: error: type mismatch;",
      " found   : org.apache.spark.sql.DataFrame",
      "    (which expands to)  org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]",
      " required: Seq[?]",
      "Error occurred in an application involving default arguments.",
      "       val RDD_vertices = sc.parallelize(df_karate_splitted)",
      "                                         ^",
      ""
     ]
    }
   ],
   "source": [
    "val RDD_vertices = sc.parallelize(df_karate_splitted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "ename": "<console>",
     "evalue": "94: error: value toDF is not a member of org.apache.spark.rdd.RDD[org.apache.spark.sql.Row]",
     "output_type": "error",
     "traceback": [
      "<console>:94: error: value toDF is not a member of org.apache.spark.rdd.RDD[org.apache.spark.sql.Row]",
      "       rows.toDF.show()",
      "            ^",
      ""
     ]
    }
   ],
   "source": [
    "rows.toDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
